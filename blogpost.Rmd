---
title: "Untitled"
author: "Boaz Sobrado"
date: "Monday, April 11, 2016"
output: html_document
---

It is a truism that we live in the information age, yet on a day to day basis we engage remarkably little with insights on the personal information we create. Sure, Netflix shows you films you want to see, Amazon offers books you want to buy and Facebook shows you pictures of cats with boobs or whatever it is you tend to click on, but explicit purpose of that is to get your money. What about using all that data to gain insights on who you are, who your friends are, what you tend to talk about? Introspection has a long history, but [Wundt](https://www.wikiwand.com/en/Wilhelm_Wundt) wasn't particularly data-driven.


A few interesting facts are shown by [WolframAlpha]() & [myPersonality]() but they are limited by what Facebook decides it is acceptable for you to share with other apps. For instance, you cannot share your Facebook message info (probably for the best) which is the most interesting bit. I decided to dig deeper and look into my Facebook data. 

##How I did it (technical stuff)

To do this I first downloaded my Facebook data ([this]() link shows you how). It comes in an html format, and I started to extract relevant information with [rvest]() when I noticed a python script on [github]() which handily converts it into [JSON format](). After a bit of fiddling (different time formats and timezones can confuse the script) I got it into JSON and using [rjson]() into R.


```{r,eval=FALSE}
#read and fix JSON file
library(rjson)

msgR<-fromJSON(file = "C:\\Users\\user1\\Desktop\\Life\\RProjects\\facebookMsg\\FB-Message-Parser\\messages.json",)
msg<-msgR[[1]]
rm(msgR)

threads<-sapply(msg,function(x) paste(x[[1]], sep ="", collapse = "-"))



thread<-vector()
sender<-vector()
date<-vector()
message<-vector()

for (i in 1:length(msg)){
  thread.length<-length(msg[[i]][[2]])
  for (a in 1:thread.length){
          thread[length(thread)+1]  <- threads[i]
         sender[length(sender)+1]   <- msg[[i]][[2]][[a]][[3]]
         date[length(date)+1]       <- msg[[i]][[2]][[a]][[2]]
         message[length(message)+1] <- msg[[i]][[2]][[a]][[1]]
  }
cat(paste0("thread ",i," involving ", threads[i]," has been completed ,
           ...its length was ", thread.length, "\n"))
}

df<-data.frame(thread,sender,date,message)
rm(message,msg,sender,thread,thread.length,threads, date)

df$date<-as.POSIXct(strptime(df$date,format = "%A, %B %e, %Y at %I:%M%p"))

df$thread<-as.character(df$thread)
df$sender<-as.character(df$sender)
df$message<-as.character(df$message)

```

Thus the data is ready for nice little plots about frequencies and such. However, one of my goals was to analyse the text, and to do that I needed to categorise threads into different languages. This was an issue because I regularly chat in four languages. I thought I would have to go through the astounding effort of categorising by hand, when a quick google search showed me the [textcat]() package, which will do it all for me.

```{r,eval=FALSE}
#first step, try text categorisation
install.packages("textcat")
library(textcat)
library(dplyr)
library(ggplot2)

#testing
df$language<-textcat(df$message)

#exploring. Unfortunately it didn't work perfectly, certain messages were classified wrong (I don't speak Basque)
select(df,message,language) %>% filter(language == "basque")%>% 
  select(message)

#So what I did was to take the language most spoken in the thread and classify it as that 
lang.m<-select(df,thread,language) %>% group_by(thread,language) %>% summarise(count = n()) %>%
  top_n(1)

df<-merge(df,lang.m,all.x = T,by = "thread")

#I removed the few remaining wrongly classified threads
df<-df %>% filter(language == "hungarian" |
              language == "english" |
              language == "spanish" |
              language == "german")

```

In addition, I thought I would classify the messages whether they were sent by a male or a female. Luckily, R provided me with a [package for this too](https://github.com/ropensci/gender).

##Results (interesting stuff?)
After a bit of cleaning and struggling with encodings the data was ready for analysis. For instance, when do I chat? When did I use Facebook Messenger the most? Who do I chat to the most? How has who I chat to changed over time? What topics do we discuss?


```{r,eval=F}
#read and fix JSON file
library(lubridate)
library(ggplot2)

years<-2016

z<-df %>%
  filter(is.null(years) | year(date) %in% years) %>% select(date)

x<-data.frame(time = strptime(paste0("2016-04-09 ",strftime(z$date,format = "%T")),format ="%Y-%m-%d %H:%M:%S" ))

ggplot(data=x, aes(x=time)) +
  geom_bar(stat="count")+
  theme(legend.position="none")
```

###when do I send messages in time?

###Who is more chatty, girls or boys? messages sent and message length

###how has who I speak to over facebook changed over time?

