arrange(date) %>% select(date, msgLen)
select(df, thread,message,msgLen,date) %>%
filter(thread == thread.selected) %>%
filter(grepl('ounce|weed|bag|MD|high|drug', message)) %>%
arrange(date) %>% select(date, msgLen) %>%
group_by(date) %>% summarise(count = sum(msgLen))
p<-select(df, thread,message,msgLen,date) %>%
filter(thread == thread.selected) %>%
filter(sender = x) %>%
filter(grepl('ounce|weed|bag|MD|high|drug', message)) %>%
arrange(date) %>% select(date, msgLen) %>%
group_by(date) %>% summarise(count = sum(msgLen))
p$who<-x
p2<-select(df,sender, thread,date) %>%
filter(thread == thread.selected) %>%
filter(sender != x) %>%
filter(grepl('ounce|weed|bag|MD|high|drug', message)) %>%
arrange(date) %>% select(date) %>%
group_by(date) %>% summarise(count = n())
p2$who<-y
p<-rbind(p,p2)
ggplot(data=p, aes(x=date,fill =who)) +
geom_bar(stat="bin", alpha=.5, position="dodge")
select(df, thread,message,msgLen,date) %>%
filter(thread == thread.selected) %>%
filter(sender = x) %>%
filter(grepl('ounce|weed|bag|MD|high|drug', message)) %>%
arrange(date) %>% select(date, msgLen) %>%
group_by(date) %>% summarise(count = sum(msgLen))
select(df, thread,message,msgLen,date) %>%
filter(thread == thread.selected) %>%
filter(grepl('ounce|weed|bag|MD|high|drug', message)) %>%
arrange(date) %>% select(date, msgLen) %>%
group_by(date) %>% summarise(count = sum(msgLen))
filter(thread == thread.selected) %>%
select(df, thread,message,msgLen,date) %>%
filter(thread == thread.selected) %>%
filter(sender = x)
thread.selected<-paste0(x,"-",y)
p<-select(df, thread,message,msgLen,date) %>%
filter(thread == thread.selected) %>%
filter(sender == x) %>%
filter(grepl('ounce|weed|bag|MD|high|drug', message)) %>%
arrange(date) %>% select(date, msgLen) %>%
group_by(date) %>% summarise(count = sum(msgLen))
p$who<-x
p2<-select(df,sender, thread,date) %>%
filter(thread == thread.selected) %>%
filter(sender != x) %>%
filter(grepl('ounce|weed|bag|MD|high|drug', message)) %>%
arrange(date) %>% select(date) %>%
group_by(date) %>% summarise(count = n())
p2$who<-y
p<-rbind(p,p2)
ggplot(data=p, aes(x=date,fill =who)) +
geom_bar(stat="bin", alpha=.5, position="dodge")
p<-select(df, thread,message,msgLen,date,sender) %>%
filter(thread == thread.selected) %>%
filter(sender == x) %>%
filter(grepl('ounce|weed|bag|MD|high|drug', message)) %>%
arrange(date) %>% select(date, msgLen) %>%
group_by(date) %>% summarise(count = sum(msgLen))
p$who<-x
p2<-select(df,thread,message,msgLen,date,sender) %>%
filter(thread == thread.selected) %>%
filter(sender != x) %>%
filter(grepl('ounce|weed|bag|MD|high|drug', message)) %>%
arrange(date) %>% select(date) %>%
group_by(date) %>% summarise(count = n())
p2$who<-y
p<-rbind(p,p2)
ggplot(data=p, aes(x=date,fill =who)) +
geom_bar(stat="bin", alpha=.5, position="dodge")
sqrt(0.25)
(1/sqrt(0.25))
(-2--2)/
1
(0-24)/(-2-2)
24/4
a<-2
-3*a^4+30*a^2-75*a
-3*a(a^2-10*a+25)
-3*a*(a^2-10*a+25)
-3*a^4+30*a^2-75*a
-3*a^3+30*a^2-75*a
x<-3
-3*x-9*y=4 |+3x
-3*x-9*y=4 #+3x
(2^-(4/3))/(54^-(4/3))
(2^-(4/3))/(54^-(4/3))
(1/2^(4/3))/(1/54^(4/3))
(54^(4/3))/2^(4/3)
(54^(4/3))
2^(4/3)
?sqrt()
(2^-(4/3))/(54^-(4/3))
(54^(4/3))/2^(4/3)
sqrt((2/9))
sqrt((2/9))*sqrt(81)
sqrt(2/9)*9
162/9
sqrt((2/9))*sqrt(81)
sqrt(18)
sqrt(24)
(-5.5)^2
5.5*5.5
-24+30.25
x<-1
(x+5.5)^2+6.25
x^2-11*x+24
(x+5.5)^2-6.25
x^2-11*x+24
((x+5.5)^2)-6.25
((x+5.5)^2)-6.25
x^2-(11*x)+24
x^2-(11*x)+24
x^2-11*x+30.25+24-30.25
24-30.25
(x+5.5)^2-6.25
(x+5.5)^2
x^2-11*x+30.25+24-30.25
x^2-11*x+30.25
(x+5.5)^2
x^2-(11*x)+24
x^2-11*x+30.25+24-30.25
x^2-11*x+30.25
(x-5.5)^2
((x-5.5)^2)-6.25
x^2-(11*x)+24
((x-5.5)^2)-6.25
((x-5.5)^2)-6.25
x<-5.5
((x-5.5)^2)-6.25
x^2-(11*x)+24
sqrt(625)
x<-2.5
((x-5.5)^2)-6.25
x<-8
((x-5.5)^2)-6.25
X<-3
((x-5.5)^2)-6.25
install.packages("textcat")
library(textcat)
textcat("angolul beszelek", "english chat", "hablo en ingles")
textcat(c("angolul beszelek", "english chat", "hablo en ingles"))
?textcat()
textcat(c("angolul beszelek", "english chat isnt great", "hablo en ingles"))
tm(control)
rm(thread.select)
rm(x)
rm(y)
rm(p)
rm(p2)
rm(control)
rm(wc)
str(df)
textcat(df$message[1:10])
print(df$message[1:10],textcat(df$message[1:10]))
paste0(df$message[1:10],textcat(df$message[1:10]))
paste0(df$message[1:100],textcat(df$message[1:100]))
df$language<-textcat(df$message)
textcat(df$message)
textcat(df$message[1:10])
Sys.time(textcat(df$message[1:10]))
system.time(1+1)
system.time(textcat(df$message[1]))
system.time(textcat(df$message[1:10]))
system.time(textcat(df$message[1:100]))
system.time(textcat(df$message[1:1000]))
34*413
(34*413)/60
234.03/6
234.03/60
rm(thread.selec.)
df$language<-textcat(df$message)
table(df$language)
data.frame(table(df$language))
data.frame(table(df$language))[,2]
plot(data.frame(table(df$language))[,2])
asc(data.frame(table(df$language))[,2])
order(data.frame(table(df$language))[,2])
data.frame(table(df$language))[,2]
table(df$language)
library(dplyr)
save.image("C:/Users/user1/Desktop/Life/RProjects/facebookMsg/finishedDataFrame.RData")
table(df$language)
select(df,message,language) %>% filter(language == afrikaans)
select(df,message,language) %>% filter(language == "afrikaans")
select(df,message,language) %>% filter(language == "afrikaans") %>% select(message)
table(df$language)
select(df,message,language) %>% filter(language == "turkish")
%>% select(message)
select(df) %>% filter(language == "turkish")%>%
select(message)
select(df,message,language) %>% filter(language == "turkish")%>%
select(message)
table(df$language)
select(df,message,language) %>% filter(language == "basque")%>%
select(message)
select(df,thread,language) %>% group_by(thread) %>% table(language)
select(df,thread,language) %>% group_by(thread) %>% count(language)
head(df)
select(df,thread,language) %>% group_by(thread) %>% summarise(this = count(language))
select(df,thread,language) %>% group_by(thread,language) %>% summarise(count = n())
select(df,thread,language) %>% group_by(thread,language) %>% summarise(count = n()) %>%
select(language,count)
select(df,thread,language) %>% group_by(thread,language) %>% summarise(count = n()) %>%
select(language,count) %>% head(10) %>% view()
select(df,thread,language) %>% group_by(thread,language) %>% summarise(count = n()) %>%
select(language,count) %>% head(10) %>% View()
select(df,thread,language) %>% group_by(thread,language) %>% summarise(count = n()) %>%
filter(max(count)) %>% head(100)%>% View()
select(df,thread,language) %>% group_by(thread,language) %>% summarise(count = n()) %>%
top_n(1) %>% head(100)%>% View()
lang.m<-select(df,thread,language) %>% group_by(thread,language) %>% summarise(count = n()) %>%
top_n(1)
df<-merge(df,lang.m,all.x = T,by = "thread")
head(df)
View(head(df))
table(df$language.x)
table(df$language.y)
colnames(df)
colnames(df)["language.x"]
colnames(df)[6]
df[1,-"language.y"]
df[1,-6]
df<-df[,-6]
df %>% filter(language == "Hungarian" |
language == "English" |
language == "Spanish" |
language == "German") %>% nrow()
colnames(df)
colnames(df)[6]
colnames(df)[6]<-"language"
df<-df[,-7]
df %>% filter(language == "Hungarian" |
language == "English" |
language == "Spanish" |
language == "German") %>% nrow()
str(df)
df %>% filter(language == "hungarian" |
language == "english" |
language == "spanish" |
language == "german") %>% nrow()
df<-df %>% filter(language == "hungarian" |
language == "english" |
language == "spanish" |
language == "german")
library(stringi)
library(dplyr)
df$date<-as.POSIXct(strptime(df$date,format = "%A, %B %e, %Y at %I:%M%p"))
df$message<-as.character(df$message)
df$msgLen<-nchar(df$message)
df$sender<-gsub(pattern = "628590366@facebook.com",replacement = "Boaz Sobrado",x = df$sender)
head(df)
table(df$language)
library(ggplot2)
ggplot(data = df, aes(x= language))+geom_bar(stat="bin")
ggplot(data = df, aes(x= language))+geom_bar(stat="count")
ggplot(data = filter(df,sender == "Boaz Sobrado"),
aes(x= language))+geom_bar(stat="count")#theme stuff is missing
ggplot(data = filter(df,sender == "Zenab  China"),
aes(x= language))+geom_bar(stat="count")#theme stuff is missing
ggplot(data = filter(df,sender == "Zsigmond Varga"),
aes(x= language))+geom_bar(stat="count")#theme stuff is missing
df %>% filter(language == "english") %>%
group_by(thread) %>% summarise(count = n()) %>%
top_n(10)
df %>% filter(language == "spanish") %>%
group_by(thread) %>% summarise(count = n()) %>%
top_n(10)
df %>% filter(language == "hungarian") %>%
group_by(thread) %>% summarise(count = n()) %>%
top_n(10)
df %>% filter(language == "spanish") %>%
group_by(thread) %>% summarise(count = n()) %>%
top_n(10)
df %>% filter(language == "german") %>%
group_by(thread) %>% summarise(count = n()) %>%
top_n(10)
chat<-df %>% filter(language == "english") %>%
select(thread,message) %>% group_by(thread) %>%
summarise(crps = paste(,sep="",collapse=""))
chat<-df %>% filter(language == "english") %>%
select(thread,message) %>% group_by(thread) %>%
summarise(crps = paste(message,sep="",collapse=""))
dim(chat)
head(chat)
str(chat)
chat$thread<-as.character(chat$thread)
nchar(chat$crps)
summary(nchar(chat$crps))
x<-c(131,2,24)
x
str(x)
names(x)
names(x)<-c("this","that","amaz")
x
rm(x)
docs<-Corpus(VectorSource(chat$crps))
library(tm)
docs<-Corpus(VectorSource(chat$crps))
docs[[30]]
as.character(docs[[30]])
head(chat)
chat<-df %>% filter(language == "english") %>%
mutate(ppl =str_count(thread, pattern = "-")) %>%
filter(ppl > 1) %>%
select(thread,message) %>% group_by(thread) %>%
summarise(crps = paste(message,sep="",collapse=""))
library(stringr)
chat<-df %>% filter(language == "english") %>%
mutate(ppl =str_count(thread, pattern = "-")) %>%
filter(ppl > 1) %>%
select(thread,message) %>% group_by(thread) %>%
summarise(crps = paste(message,sep="",collapse=""))
summary(nchar(chat$crps))
chat$thread<-as.character(chat$thread)
as.character(docs[[30]])
chat[30,1]
chat<-df %>% filter(language == "english") %>%
mutate(ppl =str_count(thread, pattern = "-")) %>%
filter(ppl == 1) %>%
select(thread,message) %>% group_by(thread) %>%
summarise(crps = paste(message,sep="",collapse=""))
chat$thread<-as.character(chat$thread)
summary(nchar(chat$crps))
docs<-Corpus(VectorSource(chat$crps))
as.character(docs[[30]])
chat[30,1]
docs <-tm_map(docs,content_transformer(tolower))
docs <-tm_map(docs,tolower)
docs <-tm_map(docs,tolower)
docs<-tm_map(docs, content_transformer(stringi::stri_trans_tolower))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeWords, stopwords('english'))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWhitespace)
docs <- tm_map(docs, stripWhitespace)
as.character(docs[30])
docs <- tm_map(docs, stemDocument)
myStopwords <- c("can", "say","one","way","use",
"also","howev","tell","will",
"much","need","take","tend","even",
"like","particular","rather","said",
"get","well","make","ask","come","end",
"first","two","help","often","may",
"might","see","someth","thing","point",
"post","look","right","now","think","‘ve ",
"‘re ","anoth","put","set","new","good",
"want","sure","kind","larg","yes,","day","etc",
"quit","sinc","attempt","lack","seen","awar",
"littl","ever","moreov","though","found","abl",
"enough","far","earli","away","achiev","draw",
"last","never","brief","bit","entir","brief",
"great","lot")
docs <- tm_map(docs, removeWords, myStopwords)
writeLines(as.character(docs[[30]]))
chat<-df %>% filter(language == "english") %>%
mutate(ppl =str_count(thread, pattern = "-")) %>%
filter(ppl == 1) %>%
select(thread,message) %>% group_by(thread) %>%
summarise(crps = paste(message,sep=" ",collapse=""))
#quick fix and explore issues
chat$thread<-as.character(chat$thread)
summary(nchar(chat$crps))
#start cleaning of character vector to create a term document matrix
docs<-Corpus(VectorSource(chat$crps))
docs<-tm_map(docs, content_transformer(stringi::stri_trans_tolower))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeWords, stopwords('english'))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
myStopwords <- c("can", "say","one","way","use",
"also","howev","tell","will",
"much","need","take","tend","even",
"like","particular","rather","said",
"get","well","make","ask","come","end",
"first","two","help","often","may",
"might","see","someth","thing","point",
"post","look","right","now","think","‘ve ",
"‘re ","anoth","put","set","new","good",
"want","sure","kind","larg","yes,","day","etc",
"quit","sinc","attempt","lack","seen","awar",
"littl","ever","moreov","though","found","abl",
"enough","far","earli","away","achiev","draw",
"last","never","brief","bit","entir","brief",
"great","lot")
docs <- tm_map(docs, removeWords, myStopwords)
#Create document-term matrix
dtm <- DocumentTermMatrix(docs)
m<-as.matrix(dtm)
#compute cosine similarity
cosineSim <- function(x){
as.dist(x%*%t(x)/(sqrt(rowSums(x^2) %*% t(rowSums(x^2)))))
}
cs <- cosineSim(m)
head(df)
getwd()
setwd("/facebookmessage")
dir
dir()
setwd(dir()[8])
getwd()
rm(list= ls())
load("C:/Users/user1/Desktop/Life/RProjects/facebookMsg/finishedDataFrame.RData")
head(df)
library(tm)
library(stringr)
library(readr)
#create character vector where each thread is one element
#filter it to two people conversations in english
chat<-df %>% filter(language == "english") %>%
mutate(ppl =str_count(thread, pattern = "-")) %>%
filter(ppl == 1) %>%
select(thread,message) %>% group_by(thread) %>%
summarise(crps = paste(message,sep=" ",collapse=""))
#quick fix and explore issues
chat$thread<-as.character(chat$thread)
summary(nchar(chat$crps))
#start cleaning of character vector to create a term document matrix
docs<-Corpus(VectorSource(chat$crps))
docs<-tm_map(docs, content_transformer(stringi::stri_trans_tolower))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeWords, stopwords('english'))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
myStopwords <- c("can", "say","one","way","use",
"also","howev","tell","will",
"much","need","take","tend","even",
"like","particular","rather","said",
"get","well","make","ask","come","end",
"first","two","help","often","may",
"might","see","someth","thing","point",
"post","look","right","now","think","‘ve ",
"‘re ","anoth","put","set","new","good",
"want","sure","kind","larg","yes,","day","etc",
"quit","sinc","attempt","lack","seen","awar",
"littl","ever","moreov","though","found","abl",
"enough","far","earli","away","achiev","draw",
"last","never","brief","bit","entir","brief",
"great","lot")
docs <- tm_map(docs, removeWords, myStopwords)
#Create document-term matrix
dtm <- DocumentTermMatrix(docs)
m<-as.matrix(dtm)
#compute cosine similarity
cosineSim <- function(x){
as.dist(x%*%t(x)/(sqrt(rowSums(x^2) %*% t(rowSums(x^2)))))
}
cs <- cosineSim(m)
#arbitrary removing of unsimilar stuff
cs[cs < max(cs)/2] <- 0
cs <- round(cs,3)
library(dplyr)
chat<-df %>% filter(language == "english") %>%
mutate(ppl =str_count(thread, pattern = "-")) %>%
filter(ppl == 1) %>%
select(thread,message) %>% group_by(thread) %>%
summarise(crps = paste(message,sep=" ",collapse=""))
#quick fix and explore issues
chat$thread<-as.character(chat$thread)
summary(nchar(chat$crps))
#start cleaning of character vector to create a term document matrix
docs<-Corpus(VectorSource(chat$crps))
docs<-tm_map(docs, content_transformer(stringi::stri_trans_tolower))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeWords, stopwords('english'))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
myStopwords <- c("can", "say","one","way","use",
"also","howev","tell","will",
"much","need","take","tend","even",
"like","particular","rather","said",
"get","well","make","ask","come","end",
"first","two","help","often","may",
"might","see","someth","thing","point",
"post","look","right","now","think","‘ve ",
"‘re ","anoth","put","set","new","good",
"want","sure","kind","larg","yes,","day","etc",
"quit","sinc","attempt","lack","seen","awar",
"littl","ever","moreov","though","found","abl",
"enough","far","earli","away","achiev","draw",
"last","never","brief","bit","entir","brief",
"great","lot")
docs <- tm_map(docs, removeWords, myStopwords)
#Create document-term matrix
dtm <- DocumentTermMatrix(docs)
m<-as.matrix(dtm)
#compute cosine similarity
cosineSim <- function(x){
as.dist(x%*%t(x)/(sqrt(rowSums(x^2) %*% t(rowSums(x^2)))))
}
cs <- cosineSim(m)
#arbitrary removing of unsimilar stuff
cs[cs < max(cs)/2] <- 0
cs <- round(cs,3)
head(chat)
chat$thread<-gsub(pattern = "628590366@facebook.com",replacement = "Boaz Sobrado",x = chat$thread)
write_csv(as.matrix(cs),file="AdjacencyMatrix.csv")
write_csv(as.matrix(cs),path = "AdjacencyMatrix.csv")
write_csv(chat$thread,path="names.csv")
write.csv(as.matrix(cs),file = "AdjacencyMatrix.csv")
write.csv(chat$thread,file="names.csv")
head(cs)
dim(cs)
str(cs)
dim(as.matrix(cs))
head(cs)
